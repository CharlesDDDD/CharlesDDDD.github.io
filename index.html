<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chunyuan Deng</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Renaissance-inspired fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,500;0,600;0,700;1,400&family=EB+Garamond:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    :root {
      /* Morandi Color Palette */
      --morandi-cream: #f5f0e8;
      --morandi-warm-white: #faf7f2;
      --morandi-sage: #8a9a7b;
      --morandi-sage-dark: #6b7a5e;
      --morandi-dusty-rose: #c9a8a0;
      --morandi-terracotta: #b8917a;
      --morandi-muted-blue: #9aabb8;
      --morandi-warm-gray: #a69e94;
      --morandi-charcoal: #4a4541;
      --morandi-soft-brown: #7d6e63;
      /* Deep Renaissance colors */
      --renaissance-burgundy: #6b3a3a;
      --renaissance-forest: #3d4f3a;
      --renaissance-deep-brown: #3a3330;
      --renaissance-ochre: #8b6914;
      --renaissance-umber: #5c4033;
    }

    body {
      background: linear-gradient(135deg, var(--morandi-warm-white) 0%, var(--morandi-cream) 50%, #f0ebe3 100%);
      min-height: 100vh;
      font-family: 'EB Garamond', 'Georgia', serif;
      color: var(--morandi-charcoal);
      line-height: 1.7;
    }

    /* Elegant link styling - deep Renaissance tones */
    a {
      color: var(--renaissance-forest);
      text-decoration: none;
      transition: all 0.3s ease;
      border-bottom: 1px solid transparent;
    }
    a:hover {
      color: var(--renaissance-burgundy);
      border-bottom: 1px solid var(--renaissance-burgundy);
      text-decoration: none;
    }

    /* Renaissance-style name - deep forest green */
    name {
      font-family: 'Cormorant Garamond', 'Georgia', serif;
      font-weight: 700;
      letter-spacing: 3px;
      color: var(--renaissance-forest);
    }

    /* Elegant headings - deep Renaissance green */
    heading {
      display: inline-block;
      font-family: 'Cormorant Garamond', 'Georgia', serif;
      font-weight: 700;
      font-size: 24px;
      color: var(--renaissance-forest);
      letter-spacing: 1.5px;
      position: relative;
    }

    /* Renaissance-style toggle buttons */
    .pub-toggle {
      display: inline-block;
      margin-left: 15px;
      vertical-align: top;
      margin-top: 2px;
    }
    .pub-toggle button {
      background: linear-gradient(135deg, var(--morandi-warm-white) 0%, var(--morandi-cream) 100%);
      border: 1px solid var(--renaissance-forest);
      color: var(--renaissance-forest);
      padding: 6px 16px;
      margin: 0 3px;
      cursor: pointer;
      font-size: 13px;
      font-family: 'Cormorant Garamond', 'Georgia', serif;
      font-weight: 600;
      transition: all 0.4s ease;
      border-radius: 2px;
      letter-spacing: 1px;
      box-shadow: 0 2px 4px rgba(61, 79, 58, 0.1);
    }
    .pub-toggle button:hover {
      background: linear-gradient(135deg, var(--renaissance-forest) 0%, var(--morandi-sage-dark) 100%);
      color: var(--morandi-warm-white);
      box-shadow: 0 3px 8px rgba(61, 79, 58, 0.25);
      transform: translateY(-1px);
    }
    .pub-toggle button.active {
      background: linear-gradient(135deg, var(--renaissance-forest) 0%, var(--morandi-sage-dark) 100%);
      color: var(--morandi-warm-white);
      box-shadow: 0 2px 6px rgba(61, 79, 58, 0.3);
    }

    .publication-section {
      display: block;
    }
    .publication-section.hidden {
      display: none;
    }

    /* Elegant year headers with Renaissance flair */
    .year-header {
      font-family: 'Cormorant Garamond', 'Georgia', serif;
      font-size: 20px;
      font-weight: 700;
      color: var(--renaissance-forest);
      margin-top: 40px;
      margin-bottom: 18px;
      padding-bottom: 8px;
      letter-spacing: 0.5px;
      border-bottom: none;
      position: relative;
    }
    .year-header::after {
      content: '';
      position: absolute;
      bottom: 0;
      left: 0;
      width: 100%;
      height: 2px;
      background: linear-gradient(90deg, var(--renaissance-forest) 0%, var(--morandi-sage) 60%, transparent 100%);
    }
    .year-header:first-of-type {
      margin-top: 25px;
    }

    /* Paper titles - bold deep forest green for visibility */
    papertitle {
      font-family: 'Cormorant Garamond', 'Georgia', serif;
      font-weight: 700;
      font-size: 17.5px;
      color: var(--renaissance-forest);
      transition: all 0.3s ease;
      letter-spacing: 0.3px;
    }
    a:hover papertitle {
      color: var(--renaissance-burgundy);
    }

    /* Venue styling */
    td em {
      display: inline-block;
      margin-top: 6px;
      color: var(--morandi-soft-brown);
      font-style: italic;
    }

    /* Strong text (author highlighting) */
    strong {
      color: var(--renaissance-forest);
      font-weight: 600;
    }

    /* Decrease space between publication blocks */
    table tbody tr td {
      padding: 12px 20px !important;
    }

    /* Subtle card effect for profile section */
    .profile-card {
      background: linear-gradient(145deg, rgba(255,255,255,0.7) 0%, rgba(250,247,242,0.5) 100%);
      border-radius: 8px;
      box-shadow: 0 4px 20px rgba(138, 154, 123, 0.08);
      backdrop-filter: blur(10px);
    }

    /* Profile image Renaissance frame effect */
    .profile-img-container img {
      border-radius: 4px;
      box-shadow:
        0 4px 15px rgba(92, 64, 51, 0.2),
        0 0 0 1px rgba(92, 64, 51, 0.15);
      transition: all 0.4s ease;
    }
    .profile-img-container img:hover {
      box-shadow:
        0 8px 25px rgba(92, 64, 51, 0.25),
        0 0 0 2px rgba(107, 58, 58, 0.2);
      transform: scale(1.02);
    }

    /* Social links styling */
    .social-links a {
      display: inline-block;
      padding: 4px 8px;
      margin: 0 2px;
      border-radius: 3px;
      transition: all 0.3s ease;
    }
    .social-links a:hover {
      background: linear-gradient(135deg, rgba(61,79,58,0.08) 0%, rgba(107,58,58,0.08) 100%);
      border-bottom: none;
    }

    /* Service and Misc sections */
    ul {
      color: var(--morandi-charcoal);
    }
    ul li {
      margin-bottom: 8px;
    }

    /* Gradient animations for blog heading and cards */
    @keyframes gradient-shift {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }

    @keyframes card-sage {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }

    @keyframes card-wine {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }

    /* Card 1: Warm olive/khaki ‚Äî matches the linear attention blog */
    .blog-card-1 {
      background: linear-gradient(135deg, #faf8f4, #f5f2ea, #f0ece2, #eae6da, #e5e1d4, #eae6da, #f0ece2, #f5f2ea, #faf8f4);
      background-size: 300% 300%;
      animation: card-sage 2s ease infinite;
    }

    .blog-card-1:hover {
      background: linear-gradient(135deg, #f7f5f0, #f2eee5, #ece8dd, #e6e2d5, #e0dcce, #e6e2d5, #ece8dd, #f2eee5, #f7f5f0);
      background-size: 300% 300%;
      animation: card-sage 1.5s ease infinite;
    }

    /* Card 2: Warm umber/parchment ‚Äî matches the ABC research blog */
    .blog-card-2 {
      background: linear-gradient(135deg, #fcf8f2, #f7f1e9, #f2eae0, #ece3d8, #e6ddd0, #ece3d8, #f2eae0, #f7f1e9, #fcf8f2);
      background-size: 300% 300%;
      animation: card-wine 2.5s ease infinite;
    }

    .blog-card-2:hover {
      background: linear-gradient(135deg, #faf5ee, #f4ede4, #eee6db, #e8dfd3, #e1d8cb, #e8dfd3, #eee6db, #f4ede4, #faf5ee);
      background-size: 300% 300%;
      animation: card-wine 1.5s ease infinite;
    }

    /* Horizontal scrolling blog container */
    .blog-scroll {
      overflow-x: auto;
      overflow-y: hidden;
      -webkit-overflow-scrolling: touch;
      padding-bottom: 8px;
      width: 100%;
    }

    .blog-scroll::-webkit-scrollbar {
      height: 5px;
    }

    .blog-scroll::-webkit-scrollbar-track {
      background: rgba(138, 154, 123, 0.06);
      border-radius: 3px;
    }

    .blog-scroll::-webkit-scrollbar-thumb {
      background: rgba(138, 154, 123, 0.2);
      border-radius: 3px;
    }

    .blog-scroll::-webkit-scrollbar-thumb:hover {
      background: rgba(138, 154, 123, 0.35);
    }

    .blog-scroll-inner {
      display: inline-flex;
      gap: 16px;
      white-space: nowrap;
    }

    .blog-scroll-inner a {
      display: inline-block;
      width: 300px;
      min-width: 300px;
      text-decoration: none;
      white-space: normal;
      vertical-align: top;
    }

    /* Mobile responsive styles */
    @media screen and (max-width: 600px) {
      body {
        overflow-x: hidden;
      }

      table[style*="max-width:800px"] {
        max-width: 100% !important;
        padding: 0 10px !important;
      }

      table {
        width: 100% !important;
        max-width: 100% !important;
      }

      table tbody tr td[style*="width:63%"] {
        width: 55% !important;
        padding: 10px 8px 10px 15px !important;
      }

      table tbody tr td[style*="width:40%"] {
        width: 45% !important;
        max-width: 45% !important;
        padding: 10px 15px 10px 8px !important;
      }

      table tbody tr td[style*="width:40%"] img {
        max-width: 100% !important;
      }

      table tbody tr td {
        padding: 10px 15px !important;
      }

      name {
        font-size: 24px !important;
      }

      heading {
        font-size: 20px !important;
      }

      body, td, th, tr, p, a {
        font-size: 13px !important;
      }

      .pub-toggle {
        margin-left: 0;
        margin-top: 10px;
        display: block;
      }

      .pub-toggle button {
        padding: 8px 14px;
        font-size: 14px;
        margin: 0 3px 5px 0;
      }

      .year-header {
        font-size: 16px;
        margin-top: 25px;
        margin-bottom: 10px;
      }

      table tbody tr td[style*="padding:20px"] {
        padding: 15px 10px !important;
      }

      p[style*="text-align:center"] {
        word-spacing: normal;
      }

      .blog-scroll-inner {
        display: flex;
        flex-direction: row;
        flex-wrap: nowrap;
        white-space: nowrap;
      }

      .blog-scroll-inner a {
        width: 240px;
        min-width: 240px;
        flex-shrink: 0;
      }

      .blog-scroll {
        margin-left: -10px;
        margin-right: -10px;
        padding-left: 10px;
        padding-right: 10px;
        overflow-x: auto;
        overflow-y: hidden;
      }

      td em {
        font-size: 14px !important;
        display: inline !important;
      }
    }
  </style>
<!-- <link rel="icon" href="images/GTVertical_TechGold.png">	 -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chunyuan Deng ÈÇìÊ∑≥Ëøú</name>
              </p>
              <p>He is a CS PhD student at <a href="https://www.rice.edu/" >Rice University</a>, advised by Prof. <a href="https://hanjiechen.github.io/">Hanjie Chen</a>. Previosly, he was also affiliated with <a href="https://yale-nlp.github.io/">Yale NLP</a> and <a href="https://www.gatech.edu/">Georgia Tech</a>. </p>
		<p>His research mainly focuses on language model architectures and understanding their mechanism and limitations. 
              </p>
              <p style="text-align:center" class="social-links">
		<a href="https://scholar.google.com/citations?user=g7Y0RHcAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
		<a href="https://twitter.com/ChunyuanDeng">Twitter/X</a> &nbsp/&nbsp
		<a href="https://github.com/CharlesDDDD">Github</a> &nbsp/&nbsp
                <a href="mailto:cd110@rice.edu">Email</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%" class="profile-img-container">
              <a href="images/Chunyuan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Chunyuan.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
       <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>üî¶ Research</heading>
              <p>
                I primarily focus on the mechanisms and interpretability of language models and I am highly motivated to understand the 'why' behind various phenomena that occur in real-world scenarios. Specifically, I am currently or potentially interested in the following aspects of LLMs:
		<ul>
	<li><strong>Model Architechture</strong>: How to explore new <strong>interpretable arch.</strong> given the same amount of computational resources. Are there any architectures, like Backpack LMs, that could achieve similar performance to transformers while being easier to reverse engineer?</li>
        <li><strong>Model Probing</strong>: How to access parametric knowledge in Language Models to understand issues related to contamination, temporal boundaries, and leverage these insights to enhance training dynamics.</li>
        <li><strong>Mech Interp</strong>: How to interpret LLMs' capabilities from the mechanistic perspective to understand their behavior (e.g., SAEs). </li>
             </ul>
		      
              </p>
            </td>
          </tr>
        </tbody></table> -->

<!-- Blog Section -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <div style="display: flex; justify-content: space-between; align-items: baseline; margin-bottom: 20px;">
                <heading style="background: linear-gradient(120deg, #b5c2aa, #a0b095, #8a9a7b, #7d8a6e, #6b7a5e, #7d8a6e, #8a9a7b, #a0b095, #b5c2aa); background-size: 400% 400%; -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; animation: gradient-shift 10s ease infinite;">‚ú® Blog</heading>
                <a href="blog/archive.html" style="font-size: 13px; font-family: 'Cormorant Garamond', serif; font-weight: 600; letter-spacing: 0.5px;">View All ‚Üí</a>
              </div>

              <!-- Horizontal Scrolling Blog Posts -->
              <div class="blog-scroll">
                <div class="blog-scroll-inner">

                  <!-- Blog Post - ABC Research Mindset (warm umber theme) -->
                  <a href="blog/abc-research-mindset.html">
                    <div class="blog-card-2" style="padding: 20px 22px; border-radius: 6px; border: 1px solid rgba(106, 78, 78, 0.15); box-shadow: 0 3px 12px rgba(106, 78, 78, 0.08); transition: all 0.3s ease; min-height: 125px; display: flex; flex-direction: column; justify-content: center;" onmouseover="this.style.transform='translateY(-3px)'; this.style.boxShadow='0 6px 20px rgba(106, 78, 78, 0.18)';" onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 3px 12px rgba(106, 78, 78, 0.08)';">
                      <div style="font-family: 'Cormorant Garamond', serif; font-size: 11px; font-weight: 600; color: #b09a92; letter-spacing: 0.5px; margin-bottom: 8px; text-align: center; opacity: 0.85;">February 2026</div>
                      <div style="font-family: 'Cormorant Garamond', serif; font-size: 17px; font-weight: 700; color: #6a4e4e; line-height: 1.4; text-align: center; letter-spacing: 0.3px; margin-bottom: 8px;">The ABC Research Mindset</div>
                      <div style="font-size: 12px; line-height: 1.45; color: #7a706a; text-align: center; opacity: 0.75;">Debiasing novelty when judging research ideas</div>
                    </div>
                  </a>

                  <!-- Blog Post - Linear Attention (warm olive theme) -->
                  <a href="blog/linear-attention-key-value.html">
                    <div class="blog-card-1" style="padding: 20px 22px; border-radius: 6px; border: 1px solid rgba(90, 85, 70, 0.15); box-shadow: 0 3px 12px rgba(90, 85, 70, 0.08); transition: all 0.3s ease; min-height: 125px; display: flex; flex-direction: column; justify-content: center;" onmouseover="this.style.transform='translateY(-3px)'; this.style.boxShadow='0 6px 20px rgba(90, 85, 70, 0.18)';" onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 3px 12px rgba(90, 85, 70, 0.08)';">
                      <div style="font-family: 'Cormorant Garamond', serif; font-size: 11px; font-weight: 600; color: #9a9482; letter-spacing: 0.5px; margin-bottom: 8px; text-align: center; opacity: 0.85;">February 2026</div>
                      <div style="font-family: 'Cormorant Garamond', serif; font-size: 17px; font-weight: 700; color: #4a4a3e; line-height: 1.4; text-align: center; letter-spacing: 0.3px; margin-bottom: 8px;">Rethinking Key-Value Relationships in Linear Attention</div>
                      <div style="font-size: 12px; line-height: 1.45; color: #6a6858; text-align: center; opacity: 0.75;">How non-linearities of key-value affect online loss in linear attention? A empirical study.</div>
                    </div>
                  </a>

                </div>
              </div>

            </td>
        </tr>
        </tbody>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>üî¶ Publications</heading>
              <div class="pub-toggle">
                <button id="recentBtn" class="active" onclick="showRecent()">Recent</button>
                <button id="allBtn" onclick="showAll()">All</button>
              </div>
              
              <!-- Recent Publications Section -->
              <div id="recentPublications" class="publication-section">
                <p>A selection of work that represents his recent research style.</p>

                <div class="year-header">Language Modeling</div>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://openreview.net/forum?id=GhJIa921j7">
                        <papertitle>ByteFlow: Language Modeling through Adaptive Byte Compression without a Tokenizer</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Sanket Lokegaonkar, Colin Lockard, Besnik Fetahu, Nasser Zalmout, Xian Li
                      <br>
                      <em>International Conference on Learning Representations</em> (<strong>ICLR</strong>), 2026.
                    </td>
                  </tr>
                </tbody></table>

                <div class="year-header">Controllability of LMs</div>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/pdf/2507.05158">
                        <papertitle>Steering Information Utility in Key-Value Memory for Language Model Post-Training</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Ruidi Chang, Hanjie Chen
                      <br>
                      <em>Advances in Neural Information Processing System</em> (<strong>NeurIPS</strong>), 2025.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2506.06686">
                        <papertitle>Learning Distribution-wise Control in Representation Space for Language Models</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Ruidi Chang, Hanjie Chen
                      <br>
                      <em>International Conference on Machine Learning</em> (<strong>ICML</strong>), 2025.
                    </td>
                  </tr>
                </tbody></table>

                <div class="year-header">Mechanisms & Limitations of LMs</div>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2410.15580">
                        <papertitle>Language Models are Symbolic Learners in Arithmetic</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Zhiqi Li, Roy Xie, Ruidi Chang, Hanjie Chen
                      <br>
                      <em>Transactions on Machine Learning Research</em> (<strong>TMLR</strong>), 2026.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2502.01025">
                        <papertitle>Language Models (Mostly) Know When to Stop Reading</papertitle>
                      </a>
                      <br>
                      Roy Xie, Junlin Wang, Paul Rosu, <strong>Chunyuan Deng</strong>, Bolun Sun, Zihao Lin, Bhuwan Dhingra
                      <br>
                      <em>Advances in Neural Information Processing System</em> (<strong>NeurIPS</strong>), 2025.
                    </td>
                  </tr>
                </tbody></table>
              </div>
              
              <!-- All Publications Section -->
              <div id="allPublications" class="publication-section hidden">
                <div class="year-header">2026</div>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <papertitle>Spherical Steering: Geometry-Aware Activation Rotation for Language Models</papertitle>
                      <br>
                      Zejia You, <strong>Chunyuan Deng</strong>, Hanjie Chen
                      <br>
                      <em>Preprint</em>, 2026.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://openreview.net/forum?id=GhJIa921j7">
                        <papertitle>ByteFlow: Language Modeling through Adaptive Byte Compression without a Tokenizer</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Sanket Lokegaonkar, Colin Lockard, Besnik Fetahu, Nasser Zalmout, Xian Li
                      <br>
                      <em>International Conference on Learning Representations</em> (<strong>ICLR</strong>), 2026.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2410.15580">
                        <papertitle>Language Models are Symbolic Learners in Arithmetic</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Zhiqi Li, Roy Xie, Ruidi Chang, Hanjie Chen
                      <br>
                      <em>Transactions on Machine Learning Research</em> (<strong>TMLR</strong>), 2026.
                    </td>
                  </tr>
                </tbody></table>

                <div class="year-header">2025</div>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/pdf/2507.05158">
                        <papertitle>Steering Information Utility in Key-Value Memory for Language Model Post-Training</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Ruidi Chang, Hanjie Chen
                      <br>
                      <em>Advances in Neural Information Processing System</em> (<strong>NeurIPS</strong>), 2025.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2502.01025">
                        <papertitle>Language Models (Mostly) Know When to Stop Reading</papertitle>
                      </a>
                      <br>
                      Roy Xie, Junlin Wang, Paul Rosu, <strong>Chunyuan Deng</strong>, Bolun Sun, Zihao Lin, Bhuwan Dhingra
                      <br>
                      <em>Advances in Neural Information Processing System</em> (<strong>NeurIPS</strong>), 2025.
                    </td>
                  </tr> 
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2507.05387">
                        <papertitle>The Generalization Ridge: Information Flow in Natural Language Generation</papertitle>
                      </a>
                      <br>
                      Ruidi Chang, <strong>Chunyuan Deng</strong>, Hanjie Chen
                      <br>
                      <em>Preprint</em>, 2025.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2502.13131">
                        <papertitle>Rethinking Diverse Human Preference Learning through Principal Component Analysis</papertitle>
                      </a>
                      <br>
                      Feng Luo, Rui Yang, Hao Sun, <strong>Chunyuan Deng</strong>, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen
                      <br>
                      <em>Findings of the Association for Computational Linguistics</em> (<strong>ACL</strong>), 2025.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2506.06686">
                        <papertitle>Learning Distribution-wise Control in Representation Space for Language Models</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Ruidi Chang, Hanjie Chen
                      <br>
                      <em>International Conference on Machine Learning</em> (<strong>ICML</strong>), 2025.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2501.16374">
                        <papertitle>SAFR: Neuron Redistribution for Interpretability</papertitle>
                      </a>
                      <br>
                      Ruidi Chang, <strong>Chunyuan Deng</strong>, Hanjie Chen
                      <br>
                      <em>Findings of the North American Chapter of the Association for Computational Linguistics</em> (<strong>NAACL</strong>), 2025 (short paper).
                    </td>
                  </tr>
                </tbody></table>
                
                <div class="year-header">2024</div>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2403.11103">
                        <papertitle>ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models</papertitle>
                      </a>
                      <br>
                      Yuzhao Heng, <strong>Chunyuan Deng</strong>, Yitong Li, Yue Yu, Yinghao Li, Rongzhi Zhang, Chao Zhang
                      <br>
                      <em>Findings of the Association for Computational Linguistics</em> (<strong>ACL</strong>), 2024.
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=g7Y0RHcAAAAJ&sortby=pubdate&citation_for_view=g7Y0RHcAAAAJ:W7OEmFMy1HYC">
                        <papertitle>Unveiling the Spectrum of Data Contamination in Language Models: A Survey from Detection to Remediation</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong><sup>‚Ä†</sup>, Yilun Zhao<sup>‚Ä†</sup>, Yuzhao Heng, Yitong Li, Jiannan Cao, Xiangru Tang, Arman Cohan
                      <br>
                      <em>Findings of the Association for Computational Linguistics</em> (<strong>ACL</strong>), 2024. (<sup>‚Ä†</sup>Equal contribution)
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2311.09783">
                        <papertitle>Investigating Data Contamination in Modern Benchmarks for Large Language Models</papertitle>
                      </a>
                      <br>
                      <strong>Chunyuan Deng</strong>, Yilun Zhao, Xiangru Tang, Mark Gerstein, Arman Cohan
                      <br>
                      <em>North American Chapter of the Association for Computational Linguistics</em> (<strong>NAACL</strong>), 2024.
                    </td>
                  </tr>
                </tbody></table>
              </div>
            </td>
        </tr>
        </tbody>
  </table> 


	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

        <tr>
            <td>
                <heading>üõ†Ô∏è Service</heading>
                <p>
                    <ul>
                        <li><strong>Program Committee/Reviewer</strong>:  ICML 2026, ICLR 2025-2026, NeurIPS 2024-2025, COLM 2024-2025, ACL ARR(2023 - now), AISTATS 2025-2026, EMNLP 2024 BlackboxNLP Workshop, NAACL 2024 Student Research Workshop. </li>
                    </ul>
                </p>
            </td>
        </tr>

</table>


			
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td>
              <heading>üéÑ Miscellaneous</heading>
	       <p>In his free time, he enjoys walking around the city photographing magnificent architecture, gorgeous scenery, and lovely interactions between human beings. üåá</p>
            </td>
          </tr>
       </table>
<script>
function showRecent() {
  document.getElementById('recentPublications').classList.remove('hidden');
  document.getElementById('allPublications').classList.add('hidden');
  document.getElementById('recentBtn').classList.add('active');
  document.getElementById('allBtn').classList.remove('active');
}

function showAll() {
  document.getElementById('recentPublications').classList.add('hidden');
  document.getElementById('allPublications').classList.remove('hidden');
  document.getElementById('recentBtn').classList.remove('active');
  document.getElementById('allBtn').classList.add('active');
}
</script>
</body>

</html>
