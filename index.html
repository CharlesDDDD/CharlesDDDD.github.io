<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chunyuan Deng</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<link rel="icon" href="images/GTVertical_TechGold.png">	
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chunyuan Deng é‚“æ·³è¿œ</name>
              </p>
              <p>I am a MS student at <a href="https://www.gatech.edu/">Georgia Institute of Technology</a> advised by Prof. <a href="http://chaozhang.org/">Chao Zhang</a>. I graduated from <a href="https://www.ecnu.edu.cn/">East China Normal University</a> with a B.Eng. in Data Science. 
              </p>
              <p>
                I am now also a research fellow working with <a href="https://yilunzhao.github.io/">Yilun Zhao</a> and Prof. <a href="https://armancohan.com/">Arman Cohan</a> at Yale NLP Group. Previously, I also worked with <a href="https://scholar.google.com/citations?user=njnBrb4AAAAJ&hl=ja">Weicheng Ma</a> and Prof. <a href="https://www.cs.dartmouth.edu/~soroush/">Soroush Vosoughi</a> at Dartmouth College.
              </p>
              <p style="text-align:center">
                <a href="mailto:cdeng73@gatech.edu">Email</a> &nbsp/&nbsp
                <a href="https://twitter.com/ChunyuanDeng">Twitter</a> &nbsp/&nbsp
		<a href="https://scholar.google.com/citations?user=g7Y0RHcAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
		<a href="https://sigmoid.social/@Chunyuan">Mastodon</a> &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/chunyuan-deng-12476417b/">LinkedIn</a> &nbsp/&nbsp		
                <a href="https://github.com/CharlesDDDD">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Chunyuan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Chunyuan.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>ðŸ”¦ Research</heading>
              <p>
                 My research interests primarily focus on the mechanisms and interpretability of language models. I am highly motivated to understand the 'why' behind various phenomena that occur in real-world scenarios." Specifically, I am currently or potentially interested in the following aspects of LLMs:
		<ul>
	<li><strong>Architechture and Training Dynamics</strong>: How to explore new architecture and training algorithms in the pretraining w. ft phases, especially from a continual learning perspective.</li>
        <li><strong>Model Probing</strong>: How to access parametric knowledge in Language Models to understand issues related to contamination, temporal boundaries, and leverage these insights to enhance training dynamics.</li>
        <li><strong>Mechanism and Interpretability</strong>: How to interpret LLMs' capabilities from a scientific and mechanistic perspective to understand their behavior. </li>
			
             </ul>
		      
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			
		  
          
	<tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mira_image'>
                  <img src='images/illustration_b.drawio.png' width="160"></div>
              </div>
             
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2311.09783">
                <papertitle>Investigating Data Contamination in Modern Benchmarks for Large Language Models</papertitle>
              </a>
              <br>
              <strong>Chunyuan Deng</strong>, Yilun Zhao, Xiangru Tang, Mark Gerstein, Arman Cohan
              <br>
	       <em>NAACL 2024 (long paper).</em>
              <p></p>
            </td>
          </tr>
	<tr>

<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mira_image'>
                  <img src='images/illustration_b.drawio.png' width="160"></div>
              </div>
             
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias towards Vision-Language Tasks</papertitle>
              </a>
              <br>
              Yunqi Zhang, Songda Li, <strong>Chunyuan Deng</strong>, Luyi Wang, Hui Zhao
              <br>
	       <em>NAACL 2024 (long paper).</em>
              <p></p>
            </td>
          </tr>
	<tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mira_image'>
                  <img src='images/illustration_b.drawio.png' width="160"></div>
              </div>
             
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Benchmark Probing: Investigating Data Leakage in Large Language Models</papertitle>
              </a>
              <br>
              <strong>Chunyuan Deng</strong>, Yilun Zhao, Xiangru Tang, Mark Gerstein, <a href="https://armancohan.com/">Arman Cohan</a>
              <br>
<!--               <em>In NeurIPS 2023 Workshop on Backdoors in Deep Learning: The Good, the Bad, and the Ugly</em> -->
	       <em>BUGS @ NeurIPS 2023 </em>
              <p></p>
            </td>
          </tr>
		<tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mira_image'>
                  <img src='images/CNCDial.png' width="160"></div>
              </div>
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2023W/VOTS/papers/Kristan_The_First_Visual_Object_Tracking_Segmentation_VOTS2023_Challenge_Results_ICCVW_2023_paper.pdf">
                <papertitle>MiOTS (MiOTS-ST): A Single-object Multi-target Tracking and Segmentation Model</papertitle>
              </a>
              <br>
              C. Wan, H. Yu, W. Yu, D. An, K. He, A. Xiao, <strong>C. Deng</strong>, J. Dong, M. Xu, X. Yin, K. Zuo
              <br>
<!--               <em>In NeurIPS 2023 Workshop on Backdoors in Deep Learning: The Good, the Bad, and the Ugly</em> -->
	       <em>VOTS @ ICCV 2023</em>
              <p></p>
            </td>
          </tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mira_image'>
                  <img src='images/illustration_b.drawio.png' width="160"></div>
              </div>
             
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Simulated Misinformation Susceptibility (SMISTS): Enhancing Misinformation Research with Large Language Model Simulations</papertitle>
              </a>
              <br>
              Weicheng Ma*, <strong>Chunyuan Deng*</strong>, Aram Moossavi, Lili Wang, Soroush Vosoughi, Diyi Yang
              <br>
	       <em>Under Review at ACL 2024 ARR</em>
              <p></p>
            </td>
          </tr>
	<tr>

		

          
          
            

          


        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>ðŸŽ„ Misc</heading>
	       <p>In my free time, I enjoy walking around the city photographing magnificent architecture, gorgeous scenery, and lovely interactions between human beings. ðŸŒ‡</p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          
          		
      </td>
    </tr>
  </table>
</body>

</html>
